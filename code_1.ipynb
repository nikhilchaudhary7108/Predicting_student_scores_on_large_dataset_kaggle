{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc937e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # excel in python\n",
    "import numpy as np  # Numerical python\n",
    "import matplotlib.pyplot as plt  # controlled visulaisation\n",
    "import seaborn as sns    # prettier ans easier visualisations\n",
    "import warnings # supress warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efae5670",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a781416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated the settings for pandas\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "print(\"Successfully updated the settings for pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2657765",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"C:\\Users\\LENOVO\\Documents\\Kaggle Competitions\\Predicting Student Test Scores\\train_dataset.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\LENOVO\\Documents\\Kaggle Competitions\\Predicting Student Test Scores\\test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05d3222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training data loaded: 630000 rows, 13 columns\n",
      "✓ Testing data loaded: 270000 rows, 12 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"✓ Training data loaded: {train_df.shape[0]} rows, {train_df.shape[1]} columns\")\n",
    "print(f\"✓ Testing data loaded: {test_df.shape[0]} rows, {test_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fd0e27",
   "metadata": {},
   "source": [
    "DATA QUALITY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "492dbc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "90c4af05-192f-40e9-9afd-8de1d1f29151",
       "rows": [
        [
         "id",
         "0"
        ],
        [
         "age",
         "0"
        ],
        [
         "gender",
         "0"
        ],
        [
         "course",
         "0"
        ],
        [
         "study_hours",
         "0"
        ],
        [
         "class_attendance",
         "0"
        ],
        [
         "internet_access",
         "0"
        ],
        [
         "sleep_hours",
         "0"
        ],
        [
         "sleep_quality",
         "0"
        ],
        [
         "study_method",
         "0"
        ],
        [
         "facility_rating",
         "0"
        ],
        [
         "exam_difficulty",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "id                  0\n",
       "age                 0\n",
       "gender              0\n",
       "course              0\n",
       "study_hours         0\n",
       "class_attendance    0\n",
       "internet_access     0\n",
       "sleep_hours         0\n",
       "sleep_quality       0\n",
       "study_method        0\n",
       "facility_rating     0\n",
       "exam_difficulty     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b35cec1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "b2414fb1-8246-4fdf-b895-ed654afaaafd",
       "rows": [
        [
         "0",
         "False"
        ],
        [
         "1",
         "False"
        ],
        [
         "2",
         "False"
        ],
        [
         "3",
         "False"
        ],
        [
         "4",
         "False"
        ],
        [
         "5",
         "False"
        ],
        [
         "6",
         "False"
        ],
        [
         "7",
         "False"
        ],
        [
         "8",
         "False"
        ],
        [
         "9",
         "False"
        ],
        [
         "10",
         "False"
        ],
        [
         "11",
         "False"
        ],
        [
         "12",
         "False"
        ],
        [
         "13",
         "False"
        ],
        [
         "14",
         "False"
        ],
        [
         "15",
         "False"
        ],
        [
         "16",
         "False"
        ],
        [
         "17",
         "False"
        ],
        [
         "18",
         "False"
        ],
        [
         "19",
         "False"
        ],
        [
         "20",
         "False"
        ],
        [
         "21",
         "False"
        ],
        [
         "22",
         "False"
        ],
        [
         "23",
         "False"
        ],
        [
         "24",
         "False"
        ],
        [
         "25",
         "False"
        ],
        [
         "26",
         "False"
        ],
        [
         "27",
         "False"
        ],
        [
         "28",
         "False"
        ],
        [
         "29",
         "False"
        ],
        [
         "30",
         "False"
        ],
        [
         "31",
         "False"
        ],
        [
         "32",
         "False"
        ],
        [
         "33",
         "False"
        ],
        [
         "34",
         "False"
        ],
        [
         "35",
         "False"
        ],
        [
         "36",
         "False"
        ],
        [
         "37",
         "False"
        ],
        [
         "38",
         "False"
        ],
        [
         "39",
         "False"
        ],
        [
         "40",
         "False"
        ],
        [
         "41",
         "False"
        ],
        [
         "42",
         "False"
        ],
        [
         "43",
         "False"
        ],
        [
         "44",
         "False"
        ],
        [
         "45",
         "False"
        ],
        [
         "46",
         "False"
        ],
        [
         "47",
         "False"
        ],
        [
         "48",
         "False"
        ],
        [
         "49",
         "False"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 630000
       }
      },
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3         False\n",
       "4         False\n",
       "          ...  \n",
       "629995    False\n",
       "629996    False\n",
       "629997    False\n",
       "629998    False\n",
       "629999    False\n",
       "Length: 630000, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = train_df.duplicated()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a10017e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "\n",
      " Initial Data Exploration\n",
      "********************************************************************************\n",
      "1. First 5 Rows of Training Dataset\n",
      "\n",
      "********************************************************************************\n",
      "   id  age  gender   course  study_hours  class_attendance internet_access  \\\n",
      "0   0   21  female     b.sc         7.91             98.80              no   \n",
      "1   1   18   other  diploma         4.95             94.80             yes   \n",
      "2   2   20  female     b.sc         4.68             92.60             yes   \n",
      "3   3   19    male     b.sc         2.00             49.50             yes   \n",
      "4   4   23    male      bca         7.65             86.90             yes   \n",
      "\n",
      "   sleep_hours sleep_quality   study_method facility_rating exam_difficulty  \\\n",
      "0         4.90       average  online videos             low            easy   \n",
      "1         4.70          poor     self-study          medium        moderate   \n",
      "2         5.80          poor       coaching            high        moderate   \n",
      "3         8.30       average    group study            high        moderate   \n",
      "4         9.60          good     self-study            high            easy   \n",
      "\n",
      "   exam_score  \n",
      "0       78.30  \n",
      "1       46.70  \n",
      "2       99.00  \n",
      "3       63.90  \n",
      "4      100.00  \n",
      "\n",
      "********************************************************************************\n",
      "2. Dataset Information :\n",
      "********************************************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 630000 entries, 0 to 629999\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   id                630000 non-null  int64  \n",
      " 1   age               630000 non-null  int64  \n",
      " 2   gender            630000 non-null  object \n",
      " 3   course            630000 non-null  object \n",
      " 4   study_hours       630000 non-null  float64\n",
      " 5   class_attendance  630000 non-null  float64\n",
      " 6   internet_access   630000 non-null  object \n",
      " 7   sleep_hours       630000 non-null  float64\n",
      " 8   sleep_quality     630000 non-null  object \n",
      " 9   study_method      630000 non-null  object \n",
      " 10  facility_rating   630000 non-null  object \n",
      " 11  exam_difficulty   630000 non-null  object \n",
      " 12  exam_score        630000 non-null  float64\n",
      "dtypes: float64(4), int64(2), object(7)\n",
      "memory usage: 62.5+ MB\n",
      "None\n",
      "\n",
      "********************************************************************************\n",
      "3.Statistical Summary of the Training Dataset : \n",
      "********************************************************************************\n",
      "             id       age  study_hours  class_attendance  sleep_hours  \\\n",
      "count 630000.00 630000.00    630000.00         630000.00    630000.00   \n",
      "mean  314999.50     20.55         4.00             71.99         7.07   \n",
      "std   181865.48      2.26         2.36             17.43         1.74   \n",
      "min        0.00     17.00         0.08             40.60         4.10   \n",
      "25%   157499.75     19.00         1.97             57.00         5.60   \n",
      "50%   314999.50     21.00         4.00             72.60         7.10   \n",
      "75%   472499.25     23.00         6.05             87.20         8.60   \n",
      "max   629999.00     24.00         7.91             99.40         9.90   \n",
      "\n",
      "       exam_score  \n",
      "count   630000.00  \n",
      "mean        62.51  \n",
      "std         18.92  \n",
      "min         19.60  \n",
      "25%         48.80  \n",
      "50%         62.60  \n",
      "75%         76.30  \n",
      "max        100.00  \n",
      "\n",
      "********************************************************************************\n",
      "Checking for missing values in training and testing datasets\n",
      "********************************************************************************\n",
      "\n",
      "Training Data Missing Values : \n",
      "No missing values !\n",
      "\n",
      "Testing Data Missing Values : \n",
      " No missing values !\n",
      "\n",
      "********************************************************************************\n",
      "5. Data Types Breakdown : \n",
      "********************************************************************************\n",
      "Numerical columns : ['id', 'age', 'study_hours', 'class_attendance', 'sleep_hours', 'exam_score']\n",
      "Categorical columns : ['gender', 'course', 'internet_access', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n",
      "\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*80)\n",
    "print(\"\\n Initial Data Exploration\")\n",
    "\n",
    "\n",
    "#1 . First 5 rows of training dataset\n",
    "print(\"*\"* 80)\n",
    "print(\"1. First 5 Rows of Training Dataset\")\n",
    "print(\"\\n\" +\"*\"* 80)\n",
    "print(train_df.head())\n",
    "\n",
    "#2 . Dataset Information\n",
    "print(\"\\n\" +\"*\"* 80)\n",
    "print(\"2. Dataset Information :\")\n",
    "print(\"*\"* 80)\n",
    "print(train_df.info())\n",
    "\n",
    "#3 . Basic Statistical information of teh training dataset\n",
    "print(\"\\n\" +\"*\"* 80)\n",
    "print(\"3.Statistical Summary of the Training Dataset : \")\n",
    "print(\"*\"*80)\n",
    "print(train_df.describe())\n",
    "\n",
    "#4 . Check for missing values in both datasets(training and testing)\n",
    "print(\"\\n\" +\"*\"* 80)\n",
    "print(\"Checking for missing values in training and testing datasets\")\n",
    "print(\"*\"*80)\n",
    "missing_train = train_df.isnull().sum()\n",
    "missing_test = test_df.isnull().sum()\n",
    "\n",
    "print(\"\\nTraining Data Missing Values : \")\n",
    "print(missing_train[missing_train > 0] if missing_train.sum() > 0 else \"No missing values !\")\n",
    "\n",
    "print(\"\\nTesting Data Missing Values : \")\n",
    "print(missing_test[missing_test > 0] if missing_test.sum() > 0 else \" No missing values !\")\n",
    "\n",
    "#5 . Data Types Breakdown\n",
    "print(\"\\n\" +\"*\"* 80)\n",
    "print(\"5. Data Types Breakdown : \")\n",
    "print(\"*\" * 80)\n",
    "print(f\"Numerical columns : {train_df.select_dtypes(include=[np.number]).columns.tolist()}\")\n",
    "print(f\"Categorical columns : {train_df.select_dtypes(include=['object']).columns.tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"*\"* 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a6ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f43a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463f6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde84c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff7198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9350fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c185629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "study_hours",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "class_attendance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sleep_hours",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exam_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9c95d712-c8f4-4883-b2d6-e3bddc6dcd47",
       "rows": [
        [
         "count",
         "630000.0",
         "630000.0",
         "630000.0",
         "630000.0",
         "630000.0",
         "630000.0"
        ],
        [
         "mean",
         "314999.5",
         "20.545820634920634",
         "4.002337406507937",
         "71.98726138412697",
         "7.072758031746031",
         "62.506672165079365"
        ],
        [
         "std",
         "181865.47913171904",
         "2.2602375224259377",
         "2.359880288493273",
         "17.43009782486794",
         "1.7448109915933214",
         "18.916884146327686"
        ],
        [
         "min",
         "0.0",
         "17.0",
         "0.08",
         "40.6",
         "4.1",
         "19.599"
        ],
        [
         "25%",
         "157499.75",
         "19.0",
         "1.97",
         "57.0",
         "5.6",
         "48.8"
        ],
        [
         "50%",
         "314999.5",
         "21.0",
         "4.0",
         "72.6",
         "7.1",
         "62.6"
        ],
        [
         "75%",
         "472499.25",
         "23.0",
         "6.05",
         "87.2",
         "8.6",
         "76.3"
        ],
        [
         "max",
         "629999.0",
         "24.0",
         "7.91",
         "99.4",
         "9.9",
         "100.0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>study_hours</th>\n",
       "      <th>class_attendance</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>exam_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>630000.000000</td>\n",
       "      <td>630000.000000</td>\n",
       "      <td>630000.000000</td>\n",
       "      <td>630000.000000</td>\n",
       "      <td>630000.000000</td>\n",
       "      <td>630000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>314999.500000</td>\n",
       "      <td>20.545821</td>\n",
       "      <td>4.002337</td>\n",
       "      <td>71.987261</td>\n",
       "      <td>7.072758</td>\n",
       "      <td>62.506672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>181865.479132</td>\n",
       "      <td>2.260238</td>\n",
       "      <td>2.359880</td>\n",
       "      <td>17.430098</td>\n",
       "      <td>1.744811</td>\n",
       "      <td>18.916884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>19.599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>157499.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.970000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>48.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>314999.500000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>72.600000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>62.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>472499.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>87.200000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>76.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>629999.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.910000</td>\n",
       "      <td>99.400000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id            age    study_hours  class_attendance  \\\n",
       "count  630000.000000  630000.000000  630000.000000     630000.000000   \n",
       "mean   314999.500000      20.545821       4.002337         71.987261   \n",
       "std    181865.479132       2.260238       2.359880         17.430098   \n",
       "min         0.000000      17.000000       0.080000         40.600000   \n",
       "25%    157499.750000      19.000000       1.970000         57.000000   \n",
       "50%    314999.500000      21.000000       4.000000         72.600000   \n",
       "75%    472499.250000      23.000000       6.050000         87.200000   \n",
       "max    629999.000000      24.000000       7.910000         99.400000   \n",
       "\n",
       "         sleep_hours     exam_score  \n",
       "count  630000.000000  630000.000000  \n",
       "mean        7.072758      62.506672  \n",
       "std         1.744811      18.916884  \n",
       "min         4.100000      19.599000  \n",
       "25%         5.600000      48.800000  \n",
       "50%         7.100000      62.600000  \n",
       "75%         8.600000      76.300000  \n",
       "max         9.900000     100.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ec323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 630000 entries, 0 to 629999\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   id                630000 non-null  int64  \n",
      " 1   age               630000 non-null  int64  \n",
      " 2   gender            630000 non-null  object \n",
      " 3   course            630000 non-null  object \n",
      " 4   study_hours       630000 non-null  float64\n",
      " 5   class_attendance  630000 non-null  float64\n",
      " 6   internet_access   630000 non-null  object \n",
      " 7   sleep_hours       630000 non-null  float64\n",
      " 8   sleep_quality     630000 non-null  object \n",
      " 9   study_method      630000 non-null  object \n",
      " 10  facility_rating   630000 non-null  object \n",
      " 11  exam_difficulty   630000 non-null  object \n",
      " 12  exam_score        630000 non-null  float64\n",
      "dtypes: float64(4), int64(2), object(7)\n",
      "memory usage: 62.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "567b9ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d912415c-f949-4d4a-a512-bd1685b987bf",
       "rows": [
        [
         "id",
         "630000"
        ],
        [
         "age",
         "8"
        ],
        [
         "gender",
         "3"
        ],
        [
         "course",
         "7"
        ],
        [
         "study_hours",
         "792"
        ],
        [
         "class_attendance",
         "617"
        ],
        [
         "internet_access",
         "2"
        ],
        [
         "sleep_hours",
         "66"
        ],
        [
         "sleep_quality",
         "3"
        ],
        [
         "study_method",
         "5"
        ],
        [
         "facility_rating",
         "3"
        ],
        [
         "exam_difficulty",
         "3"
        ],
        [
         "exam_score",
         "805"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 13
       }
      },
      "text/plain": [
       "id                  630000\n",
       "age                      8\n",
       "gender                   3\n",
       "course                   7\n",
       "study_hours            792\n",
       "class_attendance       617\n",
       "internet_access          2\n",
       "sleep_hours             66\n",
       "sleep_quality            3\n",
       "study_method             5\n",
       "facility_rating          3\n",
       "exam_difficulty          3\n",
       "exam_score             805\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63f0d413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "629983    1\n",
      "629982    1\n",
      "629981    1\n",
      "629980    1\n",
      "629979    1\n",
      "         ..\n",
      "4         1\n",
      "3         1\n",
      "2         1\n",
      "1         1\n",
      "0         1\n",
      "Name: count, Length: 630000, dtype: int64\n",
      "age\n",
      "21    86620\n",
      "23    82872\n",
      "20    80742\n",
      "19    78885\n",
      "24    77111\n",
      "18    75632\n",
      "22    74950\n",
      "17    73188\n",
      "Name: count, dtype: int64\n",
      "gender\n",
      "other     211097\n",
      "male      210593\n",
      "female    208310\n",
      "Name: count, dtype: int64\n",
      "course\n",
      "b.tech     131236\n",
      "b.sc       111554\n",
      "b.com      110932\n",
      "bca         88721\n",
      "bba         75644\n",
      "ba          61989\n",
      "diploma     49924\n",
      "Name: count, dtype: int64\n",
      "study_hours\n",
      "0.0800    14460\n",
      "7.9100    12840\n",
      "4.6900     2451\n",
      "4.6700     2147\n",
      "4.3900     1962\n",
      "          ...  \n",
      "0.2970        1\n",
      "3.0560        1\n",
      "0.4620        1\n",
      "0.5210        1\n",
      "6.0191        1\n",
      "Name: count, Length: 792, dtype: int64\n",
      "class_attendance\n",
      "99.400    15264\n",
      "40.600     6985\n",
      "89.400     2182\n",
      "97.300     2099\n",
      "99.000     2068\n",
      "          ...  \n",
      "43.120        1\n",
      "58.532        1\n",
      "52.640        1\n",
      "94.770        1\n",
      "42.790        1\n",
      "Name: count, Length: 617, dtype: int64\n",
      "internet_access\n",
      "yes    579423\n",
      "no      50577\n",
      "Name: count, dtype: int64\n",
      "sleep_hours\n",
      "9.90    18807\n",
      "4.10    17928\n",
      "9.20    12957\n",
      "6.20    12608\n",
      "9.70    12583\n",
      "        ...  \n",
      "4.41        1\n",
      "4.82        1\n",
      "4.55        1\n",
      "4.65        1\n",
      "4.62        1\n",
      "Name: count, Length: 66, dtype: int64\n",
      "sleep_quality\n",
      "poor       213675\n",
      "good       213089\n",
      "average    203236\n",
      "Name: count, dtype: int64\n",
      "study_method\n",
      "coaching         131697\n",
      "self-study       131131\n",
      "mixed            123086\n",
      "group study      123009\n",
      "online videos    121077\n",
      "Name: count, dtype: int64\n",
      "facility_rating\n",
      "medium    214082\n",
      "low       212378\n",
      "high      203540\n",
      "Name: count, dtype: int64\n",
      "exam_difficulty\n",
      "moderate    353982\n",
      "easy        176540\n",
      "hard         99478\n",
      "Name: count, dtype: int64\n",
      "exam_score\n",
      "100.000    15458\n",
      "19.599      6336\n",
      "69.400      1740\n",
      "61.300      1683\n",
      "67.300      1660\n",
      "           ...  \n",
      "22.800        71\n",
      "20.500        70\n",
      "20.100        55\n",
      "22.400        54\n",
      "21.900        35\n",
      "Name: count, Length: 805, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in train_df.columns:\n",
    "    print(train_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b946a",
   "metadata": {},
   "source": [
    "As here we have to predict a value not a category , we would go with regression models . Let's start with linear regression . But for features or columns with categorical values , we have to label encode them . So lets do this . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f9f02c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1A: Data Loading Complete\n",
      "================================================================================\n",
      "Train shape: (630000, 13)\n",
      "Test shape: (270000, 12)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1A: Import Libraries & Load Data\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Assuming you already have train_df and test_df loaded\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1A: Data Loading Complete\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093e2373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1B: Analyzing Categorical Features\n",
      "================================================================================\n",
      "\n",
      "GENDER:\n",
      "  Unique values: 3\n",
      "  Categories: ['female' 'other' 'male']\n",
      "  Value counts:\n",
      "gender\n",
      "other     211097\n",
      "male      210593\n",
      "female    208310\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "COURSE:\n",
      "  Unique values: 7\n",
      "  Categories: ['b.sc' 'diploma' 'bca' 'b.com' 'ba' 'bba' 'b.tech']\n",
      "  Value counts:\n",
      "course\n",
      "b.tech     131236\n",
      "b.sc       111554\n",
      "b.com      110932\n",
      "bca         88721\n",
      "bba         75644\n",
      "ba          61989\n",
      "diploma     49924\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "INTERNET_ACCESS:\n",
      "  Unique values: 2\n",
      "  Categories: ['no' 'yes']\n",
      "  Value counts:\n",
      "internet_access\n",
      "yes    579423\n",
      "no      50577\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "SLEEP_QUALITY:\n",
      "  Unique values: 3\n",
      "  Categories: ['average' 'poor' 'good']\n",
      "  Value counts:\n",
      "sleep_quality\n",
      "poor       213675\n",
      "good       213089\n",
      "average    203236\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "STUDY_METHOD:\n",
      "  Unique values: 5\n",
      "  Categories: ['online videos' 'self-study' 'coaching' 'group study' 'mixed']\n",
      "  Value counts:\n",
      "study_method\n",
      "coaching         131697\n",
      "self-study       131131\n",
      "mixed            123086\n",
      "group study      123009\n",
      "online videos    121077\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "FACILITY_RATING:\n",
      "  Unique values: 3\n",
      "  Categories: ['low' 'medium' 'high']\n",
      "  Value counts:\n",
      "facility_rating\n",
      "medium    214082\n",
      "low       212378\n",
      "high      203540\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "EXAM_DIFFICULTY:\n",
      "  Unique values: 3\n",
      "  Categories: ['easy' 'moderate' 'hard']\n",
      "  Value counts:\n",
      "exam_difficulty\n",
      "moderate    353982\n",
      "easy        176540\n",
      "hard         99478\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1B: Categorical Feature Analysis\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1B: Analyzing Categorical Features\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "categorical_cols = ['gender', 'course', 'internet_access', 'sleep_quality', \n",
    "                   'study_method', 'facility_rating', 'exam_difficulty']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    print(f\"  Unique values: {train_df[col].nunique()}\")\n",
    "    print(f\"  Categories: {train_df[col].unique()}\")\n",
    "    print(f\"  Value counts:\\n{train_df[col].value_counts()}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20d22bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1C: Feature Engineering\n",
      "================================================================================\n",
      "✓ Created 8 new features\n",
      "✓ Created 8 new features\n",
      "\n",
      "New shape - Train: (630000, 21), Test: (270000, 20)\n",
      "\n",
      "New features created:\n",
      "  - study_attendance_interaction\n",
      "  - sleep_study_ratio\n",
      "  - total_engagement\n",
      "  - study_hours_squared\n",
      "  - attendance_squared\n",
      "  - age_group\n",
      "  - study_intensity\n",
      "  - attendance_category\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1C: Feature Engineering - Create New Features\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1C: Feature Engineering\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"Create advanced features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Interaction Features\n",
    "    df['study_attendance_interaction'] = df['study_hours'] * df['class_attendance']\n",
    "    df['sleep_study_ratio'] = df['sleep_hours'] / (df['study_hours'] + 0.1)  # avoid division by zero\n",
    "    df['total_engagement'] = df['study_hours'] + df['class_attendance']\n",
    "    \n",
    "    # 2. Polynomial Features\n",
    "    df['study_hours_squared'] = df['study_hours'] ** 2\n",
    "    df['attendance_squared'] = df['class_attendance'] ** 2\n",
    "    \n",
    "    # 3. Age-based features\n",
    "    df['age_group'] = pd.cut(df['age'], bins=[16, 19, 21, 25], labels=['young', 'mid', 'senior'])\n",
    "    \n",
    "    # 4. Study intensity\n",
    "    df['study_intensity'] = pd.cut(df['study_hours'], \n",
    "                                   bins=[0, 2, 4, 6, 10], \n",
    "                                   labels=['low', 'medium', 'high', 'very_high'])\n",
    "    \n",
    "    # 5. Attendance category\n",
    "    df['attendance_category'] = pd.cut(df['class_attendance'], \n",
    "                                       bins=[0, 60, 80, 100], \n",
    "                                       labels=['poor', 'average', 'excellent'])\n",
    "    \n",
    "    print(f\"✓ Created {len([c for c in df.columns if c not in train_df.columns])} new features\")\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_enhanced = create_features(train_df)\n",
    "test_enhanced = create_features(test_df)\n",
    "\n",
    "print(f\"\\nNew shape - Train: {train_enhanced.shape}, Test: {test_enhanced.shape}\")\n",
    "print(f\"\\nNew features created:\")\n",
    "new_features = [col for col in train_enhanced.columns if col not in train_df.columns]\n",
    "for feat in new_features:\n",
    "    print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a77a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1D: Ordinal Encoding\n",
      "================================================================================\n",
      "✓ Encoded sleep_quality: ['poor', 'average', 'good'] → [0, 1, 2]\n",
      "✓ Encoded facility_rating: ['low', 'medium', 'high'] → [0, 1, 2]\n",
      "✓ Encoded exam_difficulty: ['easy', 'moderate', 'hard'] → [0, 1, 2]\n",
      "✓ Encoded age_group: ['young', 'mid', 'senior'] → [0, 1, 2]\n",
      "✓ Encoded study_intensity: ['low', 'medium', 'high', 'very_high'] → [0, 1, 2, 3]\n",
      "✓ Encoded attendance_category: ['poor', 'average', 'excellent'] → [0, 1, 2]\n",
      "✓ Encoded sleep_quality: ['poor', 'average', 'good'] → [0, 1, 2]\n",
      "✓ Encoded facility_rating: ['low', 'medium', 'high'] → [0, 1, 2]\n",
      "✓ Encoded exam_difficulty: ['easy', 'moderate', 'hard'] → [0, 1, 2]\n",
      "✓ Encoded age_group: ['young', 'mid', 'senior'] → [0, 1, 2]\n",
      "✓ Encoded study_intensity: ['low', 'medium', 'high', 'very_high'] → [0, 1, 2, 3]\n",
      "✓ Encoded attendance_category: ['poor', 'average', 'excellent'] → [0, 1, 2]\n",
      "\n",
      "✓ Ordinal encoding complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1D: Ordinal Encoding for Ordinal Categorical Features\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1D: Ordinal Encoding\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define ordinal mappings (based on logical order)\n",
    "ordinal_mappings = {\n",
    "    'sleep_quality': {'poor': 0, 'average': 1, 'good': 2},\n",
    "    'facility_rating': {'low': 0, 'medium': 1, 'high': 2},\n",
    "    'exam_difficulty': {'easy': 0, 'moderate': 1, 'hard': 2},\n",
    "    'age_group': {'young': 0, 'mid': 1, 'senior': 2},\n",
    "    'study_intensity': {'low': 0, 'medium': 1, 'high': 2, 'very_high': 3},\n",
    "    'attendance_category': {'poor': 0, 'average': 1, 'excellent': 2}\n",
    "}\n",
    "\n",
    "def apply_ordinal_encoding(df, mappings):\n",
    "    df = df.copy()\n",
    "    for col, mapping in mappings.items():\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(mapping)\n",
    "            print(f\"✓ Encoded {col}: {list(mapping.keys())} → {list(mapping.values())}\")\n",
    "    return df\n",
    "\n",
    "train_encoded = apply_ordinal_encoding(train_enhanced, ordinal_mappings)\n",
    "test_encoded = apply_ordinal_encoding(test_enhanced, ordinal_mappings)\n",
    "\n",
    "print(f\"\\n✓ Ordinal encoding complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9d346ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1E: One-Hot Encoding\n",
      "================================================================================\n",
      "Applying One-Hot Encoding to: ['gender', 'course', 'internet_access', 'study_method']\n",
      "\n",
      "✓ One-Hot Encoding complete!\n",
      "Final shape - Train: (630000, 30), Test: (270000, 30)\n",
      "Total features: 30\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1E: One-Hot Encoding for Nominal Categorical Features\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1E: One-Hot Encoding\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Nominal features (no inherent order)\n",
    "nominal_features = ['gender', 'course', 'internet_access', 'study_method']\n",
    "\n",
    "print(f\"Applying One-Hot Encoding to: {nominal_features}\")\n",
    "\n",
    "train_final = pd.get_dummies(train_encoded, columns=nominal_features, drop_first=True)\n",
    "test_final = pd.get_dummies(test_encoded, columns=nominal_features, drop_first=True)\n",
    "\n",
    "# Align test set columns with train set\n",
    "missing_cols = set(train_final.columns) - set(test_final.columns)\n",
    "for col in missing_cols:\n",
    "    test_final[col] = 0\n",
    "\n",
    "# Ensure same column order\n",
    "test_final = test_final[train_final.columns]\n",
    "\n",
    "print(f\"\\n✓ One-Hot Encoding complete!\")\n",
    "print(f\"Final shape - Train: {train_final.shape}, Test: {test_final.shape}\")\n",
    "print(f\"Total features: {train_final.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a5d1969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1F: PREPROCESSING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Original Features:             13\n",
      "After Feature Engineering:     21\n",
      "After All Encoding:            30\n",
      "\n",
      "                               Feature Breakdown:                               \n",
      "--------------------------------------------------------------------------------\n",
      "Original Numerical: 6\n",
      "Original Categorical: 7\n",
      "Engineered Features: 8\n",
      "One-Hot Encoded Features: 9\n",
      "\n",
      "================================================================================\n",
      "✓ PREPROCESSING COMPLETE - Ready for modeling!\n",
      "================================================================================\n",
      "\n",
      "First 3 rows of processed training data:\n",
      "   id  age  study_hours  class_attendance  sleep_hours  sleep_quality  \\\n",
      "0   0   21         7.91             98.80         4.90              1   \n",
      "1   1   18         4.95             94.80         4.70              0   \n",
      "2   2   20         4.68             92.60         5.80              0   \n",
      "\n",
      "   facility_rating  exam_difficulty  exam_score  study_attendance_interaction  \\\n",
      "0                0                0       78.30                        781.51   \n",
      "1                1                1       46.70                        469.26   \n",
      "2                2                1       99.00                        433.37   \n",
      "\n",
      "   sleep_study_ratio  total_engagement  study_hours_squared  \\\n",
      "0               0.61            106.71                62.57   \n",
      "1               0.93             99.75                24.50   \n",
      "2               1.21             97.28                21.90   \n",
      "\n",
      "   attendance_squared age_group study_intensity attendance_category  \\\n",
      "0             9761.44         1               3                   2   \n",
      "1             8987.04         0               2                   2   \n",
      "2             8574.76         1               2                   2   \n",
      "\n",
      "   gender_male  gender_other  course_b.sc  course_b.tech  course_ba  \\\n",
      "0        False         False         True          False      False   \n",
      "1        False          True        False          False      False   \n",
      "2        False         False         True          False      False   \n",
      "\n",
      "   course_bba  course_bca  course_diploma  internet_access_yes  \\\n",
      "0       False       False           False                False   \n",
      "1       False       False            True                 True   \n",
      "2       False       False           False                 True   \n",
      "\n",
      "   study_method_group study  study_method_mixed  study_method_online videos  \\\n",
      "0                     False               False                        True   \n",
      "1                     False               False                       False   \n",
      "2                     False               False                       False   \n",
      "\n",
      "   study_method_self-study  \n",
      "0                    False  \n",
      "1                     True  \n",
      "2                    False  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1F: Feature Summary\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1F: PREPROCESSING SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n{'Original Features:':<30} {train_df.shape[1]}\")\n",
    "print(f\"{'After Feature Engineering:':<30} {train_enhanced.shape[1]}\")\n",
    "print(f\"{'After All Encoding:':<30} {train_final.shape[1]}\")\n",
    "\n",
    "print(f\"\\n{'Feature Breakdown:':^80}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Original Numerical: 6\")\n",
    "print(f\"Original Categorical: 7\")\n",
    "print(f\"Engineered Features: {len(new_features)}\")\n",
    "print(f\"One-Hot Encoded Features: {train_final.shape[1] - train_enhanced.shape[1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ PREPROCESSING COMPLETE - Ready for modeling!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 3 rows of processed training data:\")\n",
    "print(train_final.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4337bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 2A: Preparing Training Data\n",
      "================================================================================\n",
      "Training features shape: (630000, 28)\n",
      "Training target shape: (630000,)\n",
      "Test features shape: (270000, 29)\n",
      "\n",
      "Target variable statistics:\n",
      "  Mean: 62.51\n",
      "  Std: 18.92\n",
      "  Min: 19.60\n",
      "  Max: 100.00\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2A: Separate Features and Target\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 2A: Preparing Training Data\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_final.drop(['exam_score', 'id'], axis=1)\n",
    "y = train_final['exam_score']\n",
    "\n",
    "# Test data (no exam_score)\n",
    "X_test = test_final.drop(['id'], axis=1)\n",
    "test_ids = test_final['id']\n",
    "\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Training target shape: {y.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(f\"  Mean: {y.mean():.2f}\")\n",
    "print(f\"  Std: {y.std():.2f}\")\n",
    "print(f\"  Min: {y.min():.2f}\")\n",
    "print(f\"  Max: {y.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6fbf8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2B: Creating Train-Validation Split\n",
      "================================================================================\n",
      "Training set: 504,000 samples (80.0%)\n",
      "Validation set: 126,000 samples (20.0%)\n",
      "\n",
      "Target distribution check:\n",
      "  Train mean: 62.51 | Validation mean: 62.51\n",
      "  Train std: 18.92 | Validation std: 18.92\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2B: Train-Validation Split\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2B: Creating Train-Validation Split\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 80-20 split with stratification on binned target\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create bins for stratification\n",
    "y_binned = pd.cut(y, bins=5, labels=False)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_binned\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]:,} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTarget distribution check:\")\n",
    "print(f\"  Train mean: {y_train.mean():.2f} | Validation mean: {y_val.mean():.2f}\")\n",
    "print(f\"  Train std: {y_train.std():.2f} | Validation std: {y_val.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aea3fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2C: Feature Scaling\n",
      "================================================================================\n",
      "Scaling 9 numerical features:\n",
      "  - age\n",
      "  - study_hours\n",
      "  - class_attendance\n",
      "  - sleep_hours\n",
      "  - study_attendance_interaction\n",
      "  - sleep_study_ratio\n",
      "  - total_engagement\n",
      "  - study_hours_squared\n",
      "  - attendance_squared\n",
      "\n",
      "✓ Scaling complete!\n",
      "\n",
      "Scaled feature statistics (study_hours example):\n",
      "  Original - Mean: 4.00, Std: 2.36\n",
      "  Scaled   - Mean: -0.0000, Std: 1.00\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2C: Feature Scaling (for Neural Networks)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2C: Feature Scaling\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical features to scale\n",
    "numerical_features = ['age', 'study_hours', 'class_attendance', 'sleep_hours',\n",
    "                     'study_attendance_interaction', 'sleep_study_ratio',\n",
    "                     'total_engagement', 'study_hours_squared', 'attendance_squared']\n",
    "\n",
    "print(f\"Scaling {len(numerical_features)} numerical features:\")\n",
    "for feat in numerical_features:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "# Create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data only\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_val_scaled[numerical_features] = scaler.transform(X_val[numerical_features])\n",
    "X_test_scaled[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "print(f\"\\n✓ Scaling complete!\")\n",
    "print(f\"\\nScaled feature statistics (study_hours example):\")\n",
    "print(f\"  Original - Mean: {X_train['study_hours'].mean():.2f}, Std: {X_train['study_hours'].std():.2f}\")\n",
    "print(f\"  Scaled   - Mean: {X_train_scaled['study_hours'].mean():.4f}, Std: {X_train_scaled['study_hours'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfe5585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2D: DATA PREPARATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Dataset Splits:                         \n",
      "  Training samples:                      504,000\n",
      "  Validation samples:                    126,000\n",
      "  Test samples:                          270,000\n",
      "  Total features:                             28\n",
      "\n",
      "Data Versions Available:                \n",
      "  ✓ Original (X_train, X_val, X_test)\n",
      "  ✓ Scaled (X_train_scaled, X_val_scaled, X_test_scaled)\n",
      "\n",
      "================================================================================\n",
      "✓ READY FOR MODEL TRAINING!\n",
      "================================================================================\n",
      "\n",
      "Top 10 Features by Correlation with Exam Score:\n",
      "study_attendance_interaction   0.80\n",
      "study_hours                    0.76\n",
      "study_intensity                0.74\n",
      "study_hours_squared            0.74\n",
      "total_engagement               0.46\n",
      "sleep_study_ratio              0.42\n",
      "class_attendance               0.36\n",
      "attendance_squared             0.36\n",
      "attendance_category            0.34\n",
      "sleep_quality                  0.24\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2D: Data Preparation Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2D: DATA PREPARATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n{'Dataset Splits:':<40}\")\n",
    "print(f\"  {'Training samples:':<35} {X_train.shape[0]:>10,}\")\n",
    "print(f\"  {'Validation samples:':<35} {X_val.shape[0]:>10,}\")\n",
    "print(f\"  {'Test samples:':<35} {X_test.shape[0]:>10,}\")\n",
    "print(f\"  {'Total features:':<35} {X_train.shape[1]:>10}\")\n",
    "\n",
    "print(f\"\\n{'Data Versions Available:':<40}\")\n",
    "print(f\"  ✓ Original (X_train, X_val, X_test)\")\n",
    "print(f\"  ✓ Scaled (X_train_scaled, X_val_scaled, X_test_scaled)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ READY FOR MODEL TRAINING!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Quick feature importance preview (correlation with target)\n",
    "print(\"\\nTop 10 Features by Correlation with Exam Score:\")\n",
    "correlations = X_train.corrwith(y_train).abs().sort_values(ascending=False)\n",
    "print(correlations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f74474e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 3A: Feature Alignment Check\n",
      "================================================================================\n",
      "Columns in train but not in test: set()\n",
      "Columns in test but not in train: {'exam_score'}\n",
      "\n",
      "✓ Alignment complete!\n",
      "Train: (504000, 29), Val: (126000, 29), Test: (270000, 29)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3A: Fix Feature Alignment & Setup\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 3A: Feature Alignment Check\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check column differences\n",
    "train_cols = set(X_train.columns)\n",
    "test_cols = set(X_test.columns)\n",
    "\n",
    "missing_in_test = train_cols - test_cols\n",
    "missing_in_train = test_cols - train_cols\n",
    "\n",
    "print(f\"Columns in train but not in test: {missing_in_test}\")\n",
    "print(f\"Columns in test but not in train: {missing_in_train}\")\n",
    "\n",
    "# Align columns\n",
    "if missing_in_train:\n",
    "    for col in missing_in_train:\n",
    "        X_train[col] = 0\n",
    "        X_val[col] = 0\n",
    "        X_train_scaled[col] = 0\n",
    "        X_val_scaled[col] = 0\n",
    "\n",
    "if missing_in_test:\n",
    "    for col in missing_in_test:\n",
    "        X_test[col] = 0\n",
    "        X_test_scaled[col] = 0\n",
    "\n",
    "# Ensure same column order\n",
    "X_test = X_test[X_train.columns]\n",
    "X_test_scaled = X_test_scaled[X_train_scaled.columns]\n",
    "\n",
    "print(f\"\\n✓ Alignment complete!\")\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56b25e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 3B: Libraries Loaded Successfully\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3B: Install Required Libraries (if needed)\n",
    "# ============================================================================\n",
    "\n",
    "! pip install lightgbm xgboost catboost -q\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 3B: Libraries Loaded Successfully\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3143a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation function defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3C: Define Evaluation Function\n",
    "# ============================================================================\n",
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"Calculate and display regression metrics\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    print(f\"  MSE:  {mse:.4f}\")\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae, 'R2': r2, 'MSE': mse}\n",
    "\n",
    "print(\"✓ Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16897147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3D: Training LightGBM (Baseline)\n",
      "================================================================================\n",
      "Training LightGBM...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "LightGBM (Train) Performance:\n",
      "  RMSE: 8.6239\n",
      "  MAE:  6.8807\n",
      "  R²:   0.7921\n",
      "  MSE:  74.3721\n",
      "\n",
      "LightGBM (Validation) Performance:\n",
      "  RMSE: 8.7634\n",
      "  MAE:  6.9857\n",
      "  R²:   0.7855\n",
      "  MSE:  76.7973\n",
      "\n",
      "⏱ Training time: 16.76 seconds\n",
      "📊 Best iteration: 998\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3D: Baseline Model 1 - LightGBM\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3D: Training LightGBM (Baseline)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# LightGBM with basic parameters\n",
    "lgbm_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "lgbm_train = lgb.Dataset(X_train, y_train)\n",
    "lgbm_val = lgb.Dataset(X_val, y_val, reference=lgbm_train)\n",
    "\n",
    "print(\"Training LightGBM...\")\n",
    "lgbm_model = lgb.train(\n",
    "    lgbm_params,\n",
    "    lgbm_train,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[lgbm_train, lgbm_val],\n",
    "    valid_names=['train', 'valid'],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "lgbm_train_pred = lgbm_model.predict(X_train)\n",
    "lgbm_val_pred = lgbm_model.predict(X_val)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "lgbm_train_metrics = evaluate_model(y_train, lgbm_train_pred, \"LightGBM (Train)\")\n",
    "lgbm_val_metrics = evaluate_model(y_val, lgbm_val_pred, \"LightGBM (Validation)\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n⏱ Training time: {training_time:.2f} seconds\")\n",
    "print(f\"📊 Best iteration: {lgbm_model.best_iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1e23a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 3A-FIX: Converting Category Columns\n",
      "================================================================================\n",
      "Category columns found: ['age_group', 'study_intensity', 'attendance_category']\n",
      "  ✓ Converted age_group to int\n",
      "  ✓ Converted study_intensity to int\n",
      "  ✓ Converted attendance_category to int\n",
      "\n",
      "✓ All dtypes fixed!\n",
      "Current dtypes:\n",
      "bool       13\n",
      "int64       8\n",
      "float64     8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3A-FIX: Convert Category Dtypes to Numeric\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 3A-FIX: Converting Category Columns\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Identify category dtype columns\n",
    "category_cols = X_train.select_dtypes(include=['category']).columns.tolist()\n",
    "print(f\"Category columns found: {category_cols}\")\n",
    "\n",
    "# Convert to numeric in all datasets\n",
    "for col in category_cols:\n",
    "    X_train[col] = X_train[col].astype(int)\n",
    "    X_val[col] = X_val[col].astype(int)\n",
    "    X_test[col] = X_test[col].astype(int)\n",
    "    X_train_scaled[col] = X_train_scaled[col].astype(int)\n",
    "    X_val_scaled[col] = X_val_scaled[col].astype(int)\n",
    "    X_test_scaled[col] = X_test_scaled[col].astype(int)\n",
    "    print(f\"  ✓ Converted {col} to int\")\n",
    "\n",
    "print(f\"\\n✓ All dtypes fixed!\")\n",
    "print(f\"Current dtypes:\\n{X_train.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85d7fe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3E: Training XGBoost (Baseline)\n",
      "================================================================================\n",
      "Training XGBoost...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "XGBoost (Train) Performance:\n",
      "  RMSE: 8.5261\n",
      "  MAE:  6.7990\n",
      "  R²:   0.7968\n",
      "  MSE:  72.6941\n",
      "\n",
      "XGBoost (Validation) Performance:\n",
      "  RMSE: 8.7568\n",
      "  MAE:  6.9784\n",
      "  R²:   0.7859\n",
      "  MSE:  76.6819\n",
      "\n",
      "⏱ Training time: 24.40 seconds\n",
      "📊 Best iteration: 997\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3E-FIXED: Training XGBoost (Baseline)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3E: Training XGBoost (Baseline)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# XGBoost with basic parameters\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "xgb_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xgb_val_dm = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = xgb.train(\n",
    "    xgb_params,\n",
    "    xgb_train,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(xgb_train, 'train'), (xgb_val_dm, 'valid')],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "xgb_train_pred = xgb_model.predict(xgb_train)\n",
    "xgb_val_pred = xgb_model.predict(xgb_val_dm)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "xgb_train_metrics = evaluate_model(y_train, xgb_train_pred, \"XGBoost (Train)\")\n",
    "xgb_val_metrics = evaluate_model(y_val, xgb_val_pred, \"XGBoost (Validation)\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n⏱ Training time: {training_time:.2f} seconds\")\n",
    "print(f\"📊 Best iteration: {xgb_model.best_iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fdce906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3F: Training CatBoost (Baseline)\n",
      "================================================================================\n",
      "Training CatBoost...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "CatBoost (Train) Performance:\n",
      "  RMSE: 8.7446\n",
      "  MAE:  6.9805\n",
      "  R²:   0.7863\n",
      "  MSE:  76.4684\n",
      "\n",
      "CatBoost (Validation) Performance:\n",
      "  RMSE: 8.7792\n",
      "  MAE:  7.0031\n",
      "  R²:   0.7848\n",
      "  MSE:  77.0744\n",
      "\n",
      "⏱ Training time: 45.87 seconds\n",
      "📊 Best iteration: 999\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3F-FIXED: Training CatBoost (Baseline)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3F: Training CatBoost (Baseline)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# CatBoost with basic parameters\n",
    "catboost_model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='RMSE',\n",
    "    eval_metric='RMSE',\n",
    "    random_seed=42,\n",
    "    verbose=False,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "print(\"Training CatBoost...\")\n",
    "catboost_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_val, y_val),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "catboost_train_pred = catboost_model.predict(X_train)\n",
    "catboost_val_pred = catboost_model.predict(X_val)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "catboost_train_metrics = evaluate_model(y_train, catboost_train_pred, \"CatBoost (Train)\")\n",
    "catboost_val_metrics = evaluate_model(y_val, catboost_val_pred, \"CatBoost (Validation)\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n⏱ Training time: {training_time:.2f} seconds\")\n",
    "print(f\"📊 Best iteration: {catboost_model.get_best_iteration()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1e5d604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3G: BASELINE MODELS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "   Model  Train_RMSE  Val_RMSE  Train_R2  Val_R2  Overfit_Gap\n",
      "LightGBM        8.62      8.76      0.79    0.79        -0.14\n",
      " XGBoost        8.53      8.76      0.80    0.79        -0.23\n",
      "CatBoost        8.74      8.78      0.79    0.78        -0.03\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Model (Validation RMSE):\n",
      "  🏆 XGBoost\n",
      "  📊 Validation RMSE: 8.7568\n",
      "  📊 Validation R²: 0.7859\n",
      "\n",
      "================================================================================\n",
      "✓ BASELINE TRAINING COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3G: Model Comparison Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3G: BASELINE MODELS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['LightGBM', 'XGBoost', 'CatBoost'],\n",
    "    'Train_RMSE': [lgbm_train_metrics['RMSE'], xgb_train_metrics['RMSE'], catboost_train_metrics['RMSE']],\n",
    "    'Val_RMSE': [lgbm_val_metrics['RMSE'], xgb_val_metrics['RMSE'], catboost_val_metrics['RMSE']],\n",
    "    'Train_R2': [lgbm_train_metrics['R2'], xgb_train_metrics['R2'], catboost_train_metrics['R2']],\n",
    "    'Val_R2': [lgbm_val_metrics['R2'], xgb_val_metrics['R2'], catboost_val_metrics['R2']],\n",
    "    'Overfit_Gap': [\n",
    "        lgbm_train_metrics['RMSE'] - lgbm_val_metrics['RMSE'],\n",
    "        xgb_train_metrics['RMSE'] - xgb_val_metrics['RMSE'],\n",
    "        catboost_train_metrics['RMSE'] - catboost_val_metrics['RMSE']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Best Model (Validation RMSE):\")\n",
    "best_idx = comparison_df['Val_RMSE'].idxmin()\n",
    "best_model = comparison_df.loc[best_idx, 'Model']\n",
    "best_rmse = comparison_df.loc[best_idx, 'Val_RMSE']\n",
    "best_r2 = comparison_df.loc[best_idx, 'Val_R2']\n",
    "\n",
    "print(f\"  🏆 {best_model}\")\n",
    "print(f\"  📊 Validation RMSE: {best_rmse:.4f}\")\n",
    "print(f\"  📊 Validation R²: {best_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ BASELINE TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d13f4e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 4A: Optuna Loaded - Ready for Hyperparameter Tuning\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4A: Install Optuna (if needed)\n",
    "# ============================================================================\n",
    "!pip install optuna -q\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 4A: Optuna Loaded - Ready for Hyperparameter Tuning\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72addf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4B: XGBoost Hyperparameter Tuning (20 trials)\n",
      "================================================================================\n",
      "Starting Optuna optimization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154c0126d1ee46b89f41216c0b9d1ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "XGBoost Tuning Results:\n",
      "  Best RMSE: 8.7533\n",
      "  Best parameters:\n",
      "    max_depth: 8\n",
      "    learning_rate: 0.020497980520950188\n",
      "    n_estimators: 1280\n",
      "    subsample: 0.8186841117373118\n",
      "    colsample_bytree: 0.6739417822102108\n",
      "    min_child_weight: 7\n",
      "    gamma: 0.3875664116805573\n",
      "    reg_alpha: 0.9394989415641891\n",
      "    reg_lambda: 0.8948273504276488\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4B-FIXED: XGBoost Hyperparameter Tuning with Optuna\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4B: XGBoost Hyperparameter Tuning (20 trials)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def xgb_objective(trial):\n",
    "    \"\"\"Optuna objective function for XGBoost\"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'tree_method': 'hist',\n",
    "        'random_state': 42,\n",
    "        'early_stopping_rounds': 50,  # Move here for newer XGBoost versions\n",
    "        \n",
    "        # Hyperparameters to tune\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Suppress Optuna logs\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Create study\n",
    "print(\"Starting Optuna optimization...\")\n",
    "xgb_study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# Optimize\n",
    "xgb_study.optimize(\n",
    "    xgb_objective,\n",
    "    n_trials=20,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"XGBoost Tuning Results:\")\n",
    "print(f\"  Best RMSE: {xgb_study.best_value:.4f}\")\n",
    "print(f\"  Best parameters:\")\n",
    "for key, value in xgb_study.best_params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd81477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4C: LightGBM Hyperparameter Tuning (20 trials)\n",
      "================================================================================\n",
      "Starting Optuna optimization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76851c16bf542259b0a8c2333dd4281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "LightGBM Tuning Results:\n",
      "  Best RMSE: 8.7507\n",
      "  Best parameters:\n",
      "    num_leaves: 95\n",
      "    learning_rate: 0.02722387465606098\n",
      "    n_estimators: 1820\n",
      "    feature_fraction: 0.6990733898150178\n",
      "    bagging_fraction: 0.9718396181497341\n",
      "    bagging_freq: 5\n",
      "    min_child_samples: 45\n",
      "    reg_alpha: 0.3214798113039978\n",
      "    reg_lambda: 0.3245009096276744\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4C-FIXED: LightGBM Hyperparameter Tuning with Optuna\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4C: LightGBM Hyperparameter Tuning (20 trials)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def lgbm_objective(trial):\n",
    "    \"\"\"Optuna objective function for LightGBM\"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbose': -1,\n",
    "        'random_state': 42,\n",
    "        \n",
    "        # Hyperparameters to tune\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Create study\n",
    "print(\"Starting Optuna optimization...\")\n",
    "lgbm_study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# Optimize\n",
    "lgbm_study.optimize(\n",
    "    lgbm_objective,\n",
    "    n_trials=20,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"LightGBM Tuning Results:\")\n",
    "print(f\"  Best RMSE: {lgbm_study.best_value:.4f}\")\n",
    "print(f\"  Best parameters:\")\n",
    "for key, value in lgbm_study.best_params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "396d907a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4D: Training Final Tuned Models\n",
      "================================================================================\n",
      "\n",
      "1. Training Tuned XGBoost...\n",
      "\n",
      "XGBoost Tuned (Train) Performance:\n",
      "  RMSE: 8.3530\n",
      "  MAE:  6.6580\n",
      "  R²:   0.8050\n",
      "  MSE:  69.7734\n",
      "\n",
      "XGBoost Tuned (Validation) Performance:\n",
      "  RMSE: 8.7533\n",
      "  MAE:  6.9728\n",
      "  R²:   0.7860\n",
      "  MSE:  76.6204\n",
      "\n",
      "2. Training Tuned LightGBM...\n",
      "\n",
      "LightGBM Tuned (Train) Performance:\n",
      "  RMSE: 8.3763\n",
      "  MAE:  6.6758\n",
      "  R²:   0.8039\n",
      "  MSE:  70.1628\n",
      "\n",
      "LightGBM Tuned (Validation) Performance:\n",
      "  RMSE: 8.7507\n",
      "  MAE:  6.9687\n",
      "  R²:   0.7862\n",
      "  MSE:  76.5747\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4D-FIXED: Train Final Tuned Models\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4D: Training Final Tuned Models\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Train tuned XGBoost\n",
    "print(\"\\n1. Training Tuned XGBoost...\")\n",
    "xgb_tuned_params = {**xgb_study.best_params, 'random_state': 42, 'early_stopping_rounds': 50}\n",
    "xgb_tuned = xgb.XGBRegressor(**xgb_tuned_params)\n",
    "xgb_tuned.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "xgb_tuned_train_pred = xgb_tuned.predict(X_train)\n",
    "xgb_tuned_val_pred = xgb_tuned.predict(X_val)\n",
    "\n",
    "xgb_tuned_train_metrics = evaluate_model(y_train, xgb_tuned_train_pred, \"XGBoost Tuned (Train)\")\n",
    "xgb_tuned_val_metrics = evaluate_model(y_val, xgb_tuned_val_pred, \"XGBoost Tuned (Validation)\")\n",
    "\n",
    "# Train tuned LightGBM\n",
    "print(\"\\n2. Training Tuned LightGBM...\")\n",
    "lgbm_tuned = lgb.LGBMRegressor(**lgbm_study.best_params, random_state=42, verbose=-1)\n",
    "lgbm_tuned.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    ")\n",
    "\n",
    "lgbm_tuned_train_pred = lgbm_tuned.predict(X_train)\n",
    "lgbm_tuned_val_pred = lgbm_tuned.predict(X_val)\n",
    "\n",
    "lgbm_tuned_train_metrics = evaluate_model(y_train, lgbm_tuned_train_pred, \"LightGBM Tuned (Train)\")\n",
    "lgbm_tuned_val_metrics = evaluate_model(y_val, lgbm_tuned_val_pred, \"LightGBM Tuned (Validation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52340815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 4E: BASELINE vs TUNED COMPARISON\n",
      "================================================================================\n",
      "\n",
      "              Model  Val_RMSE  Val_R2  Improvement\n",
      " XGBoost (Baseline)      8.76    0.79         0.00\n",
      "    XGBoost (Tuned)      8.75    0.79         0.00\n",
      "LightGBM (Baseline)      8.76    0.79         0.00\n",
      "   LightGBM (Tuned)      8.75    0.79         0.01\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Best Overall Model:\n",
      "  🏆 LightGBM (Tuned)\n",
      "  📊 Validation RMSE: 8.7507\n",
      "  📊 Validation R²: 0.7862\n",
      "\n",
      "================================================================================\n",
      "✓ HYPERPARAMETER TUNING COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4E: Baseline vs Tuned Comparison\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4E: BASELINE vs TUNED COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_final = pd.DataFrame({\n",
    "    'Model': ['XGBoost (Baseline)', 'XGBoost (Tuned)', \n",
    "              'LightGBM (Baseline)', 'LightGBM (Tuned)'],\n",
    "    'Val_RMSE': [\n",
    "        xgb_val_metrics['RMSE'],\n",
    "        xgb_tuned_val_metrics['RMSE'],\n",
    "        lgbm_val_metrics['RMSE'],\n",
    "        lgbm_tuned_val_metrics['RMSE']\n",
    "    ],\n",
    "    'Val_R2': [\n",
    "        xgb_val_metrics['R2'],\n",
    "        xgb_tuned_val_metrics['R2'],\n",
    "        lgbm_val_metrics['R2'],\n",
    "        lgbm_tuned_val_metrics['R2']\n",
    "    ],\n",
    "    'Improvement': [\n",
    "        0,\n",
    "        xgb_val_metrics['RMSE'] - xgb_tuned_val_metrics['RMSE'],\n",
    "        0,\n",
    "        lgbm_val_metrics['RMSE'] - lgbm_tuned_val_metrics['RMSE']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison_final.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "best_overall_idx = comparison_final['Val_RMSE'].idxmin()\n",
    "best_overall_model = comparison_final.loc[best_overall_idx, 'Model']\n",
    "best_overall_rmse = comparison_final.loc[best_overall_idx, 'Val_RMSE']\n",
    "best_overall_r2 = comparison_final.loc[best_overall_idx, 'Val_R2']\n",
    "\n",
    "print(\"Best Overall Model:\")\n",
    "print(f\"  🏆 {best_overall_model}\")\n",
    "print(f\"  📊 Validation RMSE: {best_overall_rmse:.4f}\")\n",
    "print(f\"  📊 Validation R²: {best_overall_r2:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ HYPERPARAMETER TUNING COMPLETE!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e898892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 5A: Creating Weighted Ensemble of Best Models\n",
      "================================================================================\n",
      "\n",
      "Testing ensemble weights:\n",
      "--------------------------------------------------------------------------------\n",
      "Weights LGBM:0.40 / XGB:0.40 / CAT:0.20\n",
      "  RMSE: 8.7430  |  R²: 0.7865\n",
      "Weights LGBM:0.50 / XGB:0.30 / CAT:0.20\n",
      "  RMSE: 8.7431  |  R²: 0.7865\n",
      "Weights LGBM:0.33 / XGB:0.33 / CAT:0.34\n",
      "  RMSE: 8.7451  |  R²: 0.7864\n",
      "Weights LGBM:0.60 / XGB:0.30 / CAT:0.10\n",
      "  RMSE: 8.7430  |  R²: 0.7865\n",
      "\n",
      "================================================================================\n",
      "Best Ensemble Configuration:\n",
      "  Weights: LGBM:0.4 / XGB:0.4 / CAT:0.2\n",
      "  RMSE: 8.7430\n",
      "  R²: 0.7865\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5A: Create Weighted Ensemble\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 5A: Creating Weighted Ensemble of Best Models\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get validation predictions from tuned models\n",
    "lgbm_val_pred_tuned = lgbm_tuned.predict(X_val)\n",
    "xgb_val_pred_tuned = xgb_tuned.predict(X_val)\n",
    "catboost_val_pred_baseline = catboost_model.predict(X_val)\n",
    "\n",
    "# Test different ensemble weights\n",
    "weights_to_test = [\n",
    "    (0.4, 0.4, 0.2),  # Equal-ish LightGBM/XGBoost, less CatBoost\n",
    "    (0.5, 0.3, 0.2),  # Favor LightGBM\n",
    "    (0.33, 0.33, 0.34),  # Equal weight\n",
    "    (0.6, 0.3, 0.1),  # Heavy LightGBM\n",
    "]\n",
    "\n",
    "print(\"\\nTesting ensemble weights:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "ensemble_results = []\n",
    "for w1, w2, w3 in weights_to_test:\n",
    "    ensemble_pred = (w1 * lgbm_val_pred_tuned + \n",
    "                     w2 * xgb_val_pred_tuned + \n",
    "                     w3 * catboost_val_pred_baseline)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_val, ensemble_pred))\n",
    "    r2 = r2_score(y_val, ensemble_pred)\n",
    "    \n",
    "    ensemble_results.append({\n",
    "        'Weights': f\"LGBM:{w1}/XGB:{w2}/CAT:{w3}\",\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"Weights LGBM:{w1:.2f} / XGB:{w2:.2f} / CAT:{w3:.2f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}  |  R²: {r2:.4f}\")\n",
    "\n",
    "# Find best ensemble\n",
    "ensemble_df = pd.DataFrame(ensemble_results)\n",
    "best_ensemble_idx = ensemble_df['RMSE'].idxmin()\n",
    "best_weights = weights_to_test[best_ensemble_idx]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Best Ensemble Configuration:\")\n",
    "print(f\"  Weights: LGBM:{best_weights[0]} / XGB:{best_weights[1]} / CAT:{best_weights[2]}\")\n",
    "print(f\"  RMSE: {ensemble_df.loc[best_ensemble_idx, 'RMSE']:.4f}\")\n",
    "print(f\"  R²: {ensemble_df.loc[best_ensemble_idx, 'R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ad306df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5B: Retraining Best Models on Full Dataset\n",
      "================================================================================\n",
      "\n",
      "Full training set size: 630,000 samples\n",
      "Features: 29\n",
      "\n",
      "1. Retraining LightGBM (Tuned) on full dataset...\n",
      "   ✓ LightGBM training complete\n",
      "\n",
      "2. Retraining XGBoost (Tuned) on full dataset...\n",
      "   ✓ XGBoost training complete\n",
      "\n",
      "3. Retraining CatBoost (Baseline) on full dataset...\n",
      "   ✓ CatBoost training complete\n",
      "\n",
      "================================================================================\n",
      "✓ All models retrained on full 630,000 samples!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5B: Retrain on Full Dataset (Train + Validation)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5B: Retraining Best Models on Full Dataset\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Combine train and validation sets\n",
    "X_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "print(f\"\\nFull training set size: {X_full.shape[0]:,} samples\")\n",
    "print(f\"Features: {X_full.shape[1]}\")\n",
    "\n",
    "# Retrain LightGBM on full data\n",
    "print(\"\\n1. Retraining LightGBM (Tuned) on full dataset...\")\n",
    "lgbm_final = lgb.LGBMRegressor(**lgbm_study.best_params, random_state=42, verbose=-1)\n",
    "lgbm_final.fit(X_full, y_full)\n",
    "print(\"   ✓ LightGBM training complete\")\n",
    "\n",
    "# Retrain XGBoost on full data\n",
    "print(\"\\n2. Retraining XGBoost (Tuned) on full dataset...\")\n",
    "xgb_final_params = {**xgb_study.best_params, 'random_state': 42, 'early_stopping_rounds': None}\n",
    "xgb_final = xgb.XGBRegressor(**xgb_final_params)\n",
    "xgb_final.fit(X_full, y_full)\n",
    "print(\"   ✓ XGBoost training complete\")\n",
    "\n",
    "# Retrain CatBoost on full data\n",
    "print(\"\\n3. Retraining CatBoost (Baseline) on full dataset...\")\n",
    "catboost_final = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='RMSE',\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "catboost_final.fit(X_full, y_full)\n",
    "print(\"   ✓ CatBoost training complete\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ All models retrained on full 630,000 samples!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21596d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5C: Generating Test Set Predictions\n",
      "================================================================================\n",
      "\n",
      "Generating predictions from each model...\n",
      "✓ LightGBM predictions: 270,000 samples\n",
      "✓ XGBoost predictions: 270,000 samples\n",
      "✓ CatBoost predictions: 270,000 samples\n",
      "\n",
      "✓ Ensemble predictions: 270,000 samples\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Test Predictions Summary:\n",
      "--------------------------------------------------------------------------------\n",
      "Model                Mean       Std        Min        Max       \n",
      "--------------------------------------------------------------------------------\n",
      "LightGBM             62.52      16.76      15.19      103.16    \n",
      "XGBoost              62.52      16.75      14.15      103.67    \n",
      "CatBoost             62.52      16.72      14.69      104.46    \n",
      "Ensemble             62.52      16.74      15.07      103.36    \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sanity Check:\n",
      "  Expected score range: [19.6, 100.0] (from training data)\n",
      "  Actual predictions range: [15.07, 103.36]\n",
      "  ✓ Predictions within reasonable range!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5C: Generate Test Predictions\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5C: Generating Test Set Predictions\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Individual model predictions\n",
    "print(\"\\nGenerating predictions from each model...\")\n",
    "lgbm_test_pred = lgbm_final.predict(X_test)\n",
    "xgb_test_pred = xgb_final.predict(X_test)\n",
    "catboost_test_pred = catboost_final.predict(X_test)\n",
    "\n",
    "print(f\"✓ LightGBM predictions: {len(lgbm_test_pred):,} samples\")\n",
    "print(f\"✓ XGBoost predictions: {len(xgb_test_pred):,} samples\")\n",
    "print(f\"✓ CatBoost predictions: {len(catboost_test_pred):,} samples\")\n",
    "\n",
    "# Create ensemble prediction using best weights\n",
    "w1, w2, w3 = best_weights\n",
    "ensemble_test_pred = (w1 * lgbm_test_pred + \n",
    "                      w2 * xgb_test_pred + \n",
    "                      w3 * catboost_test_pred)\n",
    "\n",
    "print(f\"\\n✓ Ensemble predictions: {len(ensemble_test_pred):,} samples\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Test Predictions Summary:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Model':<20} {'Mean':<10} {'Std':<10} {'Min':<10} {'Max':<10}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'LightGBM':<20} {lgbm_test_pred.mean():<10.2f} {lgbm_test_pred.std():<10.2f} {lgbm_test_pred.min():<10.2f} {lgbm_test_pred.max():<10.2f}\")\n",
    "print(f\"{'XGBoost':<20} {xgb_test_pred.mean():<10.2f} {xgb_test_pred.std():<10.2f} {xgb_test_pred.min():<10.2f} {xgb_test_pred.max():<10.2f}\")\n",
    "print(f\"{'CatBoost':<20} {catboost_test_pred.mean():<10.2f} {catboost_test_pred.std():<10.2f} {catboost_test_pred.min():<10.2f} {catboost_test_pred.max():<10.2f}\")\n",
    "print(f\"{'Ensemble':<20} {ensemble_test_pred.mean():<10.2f} {ensemble_test_pred.std():<10.2f} {ensemble_test_pred.min():<10.2f} {ensemble_test_pred.max():<10.2f}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Sanity check\n",
    "print(\"\\nSanity Check:\")\n",
    "print(f\"  Expected score range: [19.6, 100.0] (from training data)\")\n",
    "print(f\"  Actual predictions range: [{ensemble_test_pred.min():.2f}, {ensemble_test_pred.max():.2f}]\")\n",
    "if ensemble_test_pred.min() >= 15 and ensemble_test_pred.max() <= 105:\n",
    "    print(\"  ✓ Predictions within reasonable range!\")\n",
    "else:\n",
    "    print(\"  ⚠ Warning: Predictions outside expected range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0417a374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5D: Creating Submission Files\n",
      "================================================================================\n",
      "\n",
      "✓ Submission files created:\n",
      "  1. submission_ensemble.csv (RECOMMENDED - Best ensemble)\n",
      "  2. submission_lgbm_tuned.csv (LightGBM only)\n",
      "  3. submission_xgb_tuned.csv (XGBoost only)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Preview of submission_ensemble.csv:\n",
      "--------------------------------------------------------------------------------\n",
      "       id  exam_score\n",
      "0  630000       70.98\n",
      "1  630001       70.38\n",
      "2  630002       87.29\n",
      "3  630003       55.60\n",
      "4  630004       47.56\n",
      "5  630005       72.14\n",
      "6  630006       73.17\n",
      "7  630007       59.03\n",
      "8  630008       79.15\n",
      "9  630009       90.04\n",
      "\n",
      "Total predictions: 270,000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Submission Validation:\n",
      "--------------------------------------------------------------------------------\n",
      "  ✓ Columns: ['id', 'exam_score']\n",
      "  ✓ Shape: (270000, 2)\n",
      "  ✓ No missing values: True\n",
      "  ✓ ID range: [630000, 899999]\n",
      "  ✓ Score range: [15.07, 103.36]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5D: Create Submission Files\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5D: Creating Submission Files\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create submission dataframe for ensemble\n",
    "submission_ensemble = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'exam_score': ensemble_test_pred\n",
    "})\n",
    "\n",
    "# Create individual model submissions (for comparison)\n",
    "submission_lgbm = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'exam_score': lgbm_test_pred\n",
    "})\n",
    "\n",
    "submission_xgb = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'exam_score': xgb_test_pred\n",
    "})\n",
    "\n",
    "# Save submissions\n",
    "submission_ensemble.to_csv('submission_ensemble.csv', index=False)\n",
    "submission_lgbm.to_csv('submission_lgbm_tuned.csv', index=False)\n",
    "submission_xgb.to_csv('submission_xgb_tuned.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Submission files created:\")\n",
    "print(\"  1. submission_ensemble.csv (RECOMMENDED - Best ensemble)\")\n",
    "print(\"  2. submission_lgbm_tuned.csv (LightGBM only)\")\n",
    "print(\"  3. submission_xgb_tuned.csv (XGBoost only)\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Preview of submission_ensemble.csv:\")\n",
    "print(\"-\" * 80)\n",
    "print(submission_ensemble.head(10))\n",
    "print(f\"\\nTotal predictions: {len(submission_ensemble):,}\")\n",
    "\n",
    "# Verify submission format\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Submission Validation:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"  ✓ Columns: {list(submission_ensemble.columns)}\")\n",
    "print(f\"  ✓ Shape: {submission_ensemble.shape}\")\n",
    "print(f\"  ✓ No missing values: {submission_ensemble.isnull().sum().sum() == 0}\")\n",
    "print(f\"  ✓ ID range: [{submission_ensemble['id'].min()}, {submission_ensemble['id'].max()}]\")\n",
    "print(f\"  ✓ Score range: [{submission_ensemble['exam_score'].min():.2f}, {submission_ensemble['exam_score'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ce20e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5E: FINAL PROJECT SUMMARY\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROJECT COMPLETION REPORT\n",
      "================================================================================\n",
      "\n",
      "📊 DATASET:\n",
      "  Training samples: 630,000\n",
      "  Test samples: 270,000\n",
      "  Original features: 13\n",
      "  Engineered features: 30\n",
      "\n",
      "🔧 PREPROCESSING:\n",
      "  Feature engineering: 8 new features created\n",
      "  Best feature: study_attendance_interaction (corr: 0.80)\n",
      "  Encoding: Ordinal (6) + One-Hot (4)\n",
      "  Scaling: StandardScaler on 9 numerical features\n",
      "\n",
      "🤖 MODELS TESTED:\n",
      "  1. LightGBM (Baseline): Val RMSE = 8.7634\n",
      "  2. XGBoost (Baseline): Val RMSE = 8.7568\n",
      "  3. CatBoost (Baseline): Val RMSE = 8.7792\n",
      "  4. LightGBM (Tuned): Val RMSE = 8.7507 ⭐\n",
      "  5. XGBoost (Tuned): Val RMSE = 8.7533\n",
      "  6. Ensemble: Val RMSE = 8.7430 🏆\n",
      "\n",
      "📈 FINAL PERFORMANCE (Validation Set):\n",
      "  Best Model: Ensemble\n",
      "  RMSE: 8.7430\n",
      "  MAE: ~6.97\n",
      "  R²: 0.7865\n",
      "  Variance Explained: 78.65%\n",
      "\n",
      "📁 DELIVERABLES:\n",
      "  ✓ submission_ensemble.csv (270,000 predictions)\n",
      "  ✓ submission_lgbm_tuned.csv\n",
      "  ✓ submission_xgb_tuned.csv\n",
      "  ✓ README.md (comprehensive documentation)\n",
      "\n",
      "🎯 NEXT STEPS:\n",
      "  1. Upload submission_ensemble.csv to Kaggle\n",
      "  2. Check public leaderboard score\n",
      "  3. Compare with validation RMSE (8.75)\n",
      "  4. If needed, try alternative ensembles\n",
      "\n",
      "================================================================================\n",
      "✓ PROJECT COMPLETE - READY FOR SUBMISSION!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5E: Final Summary Report\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5E: FINAL PROJECT SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROJECT COMPLETION REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n📊 DATASET:\")\n",
    "print(f\"  Training samples: 630,000\")\n",
    "print(f\"  Test samples: 270,000\")\n",
    "print(f\"  Original features: 13\")\n",
    "print(f\"  Engineered features: 30\")\n",
    "\n",
    "print(\"\\n🔧 PREPROCESSING:\")\n",
    "print(f\"  Feature engineering: 8 new features created\")\n",
    "print(f\"  Best feature: study_attendance_interaction (corr: 0.80)\")\n",
    "print(f\"  Encoding: Ordinal (6) + One-Hot (4)\")\n",
    "print(f\"  Scaling: StandardScaler on 9 numerical features\")\n",
    "\n",
    "print(\"\\n🤖 MODELS TESTED:\")\n",
    "print(f\"  1. LightGBM (Baseline): Val RMSE = 8.7634\")\n",
    "print(f\"  2. XGBoost (Baseline): Val RMSE = 8.7568\")\n",
    "print(f\"  3. CatBoost (Baseline): Val RMSE = 8.7792\")\n",
    "print(f\"  4. LightGBM (Tuned): Val RMSE = 8.7507 ⭐\")\n",
    "print(f\"  5. XGBoost (Tuned): Val RMSE = 8.7533\")\n",
    "print(f\"  6. Ensemble: Val RMSE = {ensemble_df.loc[best_ensemble_idx, 'RMSE']:.4f} 🏆\")\n",
    "\n",
    "print(\"\\n📈 FINAL PERFORMANCE (Validation Set):\")\n",
    "print(f\"  Best Model: {'Ensemble' if ensemble_df.loc[best_ensemble_idx, 'RMSE'] < 8.7507 else 'LightGBM (Tuned)'}\")\n",
    "print(f\"  RMSE: {min(ensemble_df.loc[best_ensemble_idx, 'RMSE'], 8.7507):.4f}\")\n",
    "print(f\"  MAE: ~6.97\")\n",
    "print(f\"  R²: {max(ensemble_df.loc[best_ensemble_idx, 'R2'], 0.7862):.4f}\")\n",
    "print(f\"  Variance Explained: {max(ensemble_df.loc[best_ensemble_idx, 'R2'], 0.7862)*100:.2f}%\")\n",
    "\n",
    "print(\"\\n📁 DELIVERABLES:\")\n",
    "print(f\"  ✓ submission_ensemble.csv (270,000 predictions)\")\n",
    "print(f\"  ✓ submission_lgbm_tuned.csv\")\n",
    "print(f\"  ✓ submission_xgb_tuned.csv\")\n",
    "print(f\"  ✓ README.md (comprehensive documentation)\")\n",
    "\n",
    "print(\"\\n🎯 NEXT STEPS:\")\n",
    "print(f\"  1. Upload submission_ensemble.csv to Kaggle\")\n",
    "print(f\"  2. Check public leaderboard score\")\n",
    "print(f\"  3. Compare with validation RMSE (8.75)\")\n",
    "print(f\"  4. If needed, try alternative ensembles\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ PROJECT COMPLETE - READY FOR SUBMISSION!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340df35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
